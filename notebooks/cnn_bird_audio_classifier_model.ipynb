{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import librosa as li\n",
    "import numpy as np\n",
    "import opendatasets as od\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import signal\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target sample rate for resampling audio files\n",
    "SAMPLE_RATE = 16000\n",
    "\n",
    "# Target length for audio segments (in seconds)\n",
    "SAMPLE_LENGTH = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preparation function declarations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate butterworth highpass coefficients\n",
    "def butter_highpass(cutoff, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    b, a = signal.butter(order, normal_cutoff, btype=\"high\", analog=False)\n",
    "    return b, a\n",
    "\n",
    "\n",
    "# Apply filter to signal\n",
    "def apply_butter_highpass(data, cutoff, fs, order=5):\n",
    "    b, a = butter_highpass(cutoff, fs, order=order)\n",
    "    y = signal.filtfilt(b, a, data)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove sections of silence or low intensity signal\n",
    "def remove_silence(signal, thresh=18, hop=2048, plot=False):\n",
    "    splits = li.effects.split(\n",
    "        y=signal, top_db=thresh, frame_length=(hop * 2), hop_length=hop\n",
    "    )\n",
    "    if plot:\n",
    "        peak = np.max(signal)\n",
    "        plt.subplots(figsize=(12, 4))\n",
    "        plt.plot(signal)\n",
    "        plt.vlines(splits, ymin=-peak, ymax=peak, color=\"red\")\n",
    "        plt.show()\n",
    "\n",
    "    stripped_audio = []\n",
    "\n",
    "    for s in splits:\n",
    "        split = signal[s[0]: s[1]]\n",
    "        stripped_audio.extend(split)\n",
    "\n",
    "    return np.asarray(stripped_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split audio into segments of desired length\n",
    "def split_audio(signal, target_length, samplerate, plot=False):\n",
    "    duration = li.get_duration(y=signal, sr=samplerate)\n",
    "    n_segments = np.ceil(duration / target_length)\n",
    "    audio_segments = []\n",
    "\n",
    "    for n in range(int(n_segments)):\n",
    "        s = signal[\n",
    "            samplerate * n * target_length: samplerate * (n + 1) * target_length\n",
    "        ]\n",
    "\n",
    "        if len(s) < target_length * samplerate:\n",
    "            s = np.pad(s, (0, target_length * samplerate - len(s)), \"constant\")\n",
    "\n",
    "        audio_segments.append(s)\n",
    "\n",
    "        if plot:\n",
    "            plt.plot(s, alpha=1 / n_segments)\n",
    "\n",
    "    if plot:\n",
    "        plt.show()\n",
    "\n",
    "    return audio_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply all signal processing functions to audio and return segments\n",
    "def generate_preprocessed_samples(path, sr, length, hp=700):\n",
    "\n",
    "    y, sr = li.load(path, sr=sr, mono=True)  # Load audio file\n",
    "\n",
    "    y = apply_butter_highpass(\n",
    "        data=y, cutoff=hp, fs=sr, order=5\n",
    "    )  # Apply high-pass filter\n",
    "\n",
    "    # Delete silent sections\n",
    "    y = remove_silence(y, thresh=18, hop=2048, plot=False)\n",
    "\n",
    "    audio_segments = split_audio(\n",
    "        y, target_length=length, samplerate=sr\n",
    "    )  # Split into segments of desired length\n",
    "\n",
    "    return audio_segments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset initial preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading british-birdsong-dataset.zip to ..\\datasets\\british-birdsong-dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 633M/633M [00:23<00:00, 27.8MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_url = (\n",
    "    \"https://www.kaggle.com/datasets/rtatman/british-birdsong-dataset?resource=download\"\n",
    ")\n",
    "dowload_path = \"..\\\\datasets\\\\\"\n",
    "\n",
    "od.download(dataset_url, data_dir=dowload_path)\n",
    "\n",
    "dataset_path = dowload_path + \"british-birdsong-dataset\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse metadata csv\n",
    "metadata = pd.read_csv(\n",
    "    dataset_path + \"birdsong_metadata.csv\",\n",
    "    usecols=[\"file_id\", \"genus\", \"species\", \"english_cname\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created new folder: ..\\datasets\\british-birdsong-dataset\\audio\\\n",
      "Finished dataset preprocessing!\n"
     ]
    }
   ],
   "source": [
    "# Preprocess and split audio files to target length.\n",
    "# Save samples using scientific name to corresponding subfolders.\n",
    "old_path = dataset_path + \"songs\\\\songs\\\\\"\n",
    "audio_path = dataset_path + \"audio\\\\\"\n",
    "\n",
    "try:\n",
    "    os.mkdir(audio_path)\n",
    "    print(\"Created new folder: \" + audio_path)\n",
    "except:\n",
    "    print(audio_path + \" already exists\\n\")\n",
    "\n",
    "for file in os.listdir(old_path):\n",
    "    id = file.lstrip(\"xc\").rstrip(\".flac\")\n",
    "    data = metadata.loc[metadata[\"file_id\"] == int(id)]\n",
    "\n",
    "    name = data[\"genus\"].item() + \"_\" + data[\"species\"].item()\n",
    "    subfolder = audio_path + name + \"\\\\\"\n",
    "    try:\n",
    "        os.mkdir(subfolder)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Preprocess audio and get segments of desired length\n",
    "    audio_segments = generate_preprocessed_samples(\n",
    "        old_path + file, sr=SAMPLE_RATE, length=SAMPLE_LENGTH\n",
    "    )\n",
    "\n",
    "    # Iterate through splitted audio segments and save each one as a separate flac file\n",
    "    for i, segment in enumerate(audio_segments):\n",
    "        new_filename = f\"{subfolder}{name}_{id}_{i}.flac\"\n",
    "        sf.write(new_filename, segment, SAMPLE_RATE,\n",
    "                 format=\"flac\", subtype=\"PCM_16\")\n",
    "\n",
    "shutil.rmtree(dataset_path + \"\\\\songs\")\n",
    "\n",
    "print(\"Finished generating audio samples!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataset path\n",
    "dataset_path = \"..\\\\datasets\\\\british-birdsong-dataset\\\\\"\n",
    "# Get audio path\n",
    "audio_path = dataset_path + \"audio\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_audio_dataset(data_path, json_path=None, mfcc_count=13, hop=512, fft_len=2048):\n",
    "    data_dict = {\n",
    "        'label_map': [],\n",
    "        \"encoded_labels\": [],\n",
    "        \"mfccs\": [],\n",
    "        \"files\": [],\n",
    "    }\n",
    "\n",
    "    for i, (path, _, files) in enumerate(os.walk(data_path)):\n",
    "        if path == data_path:  # Ignore parent folder\n",
    "            continue\n",
    "\n",
    "        # Add unique labels to label_map list\n",
    "        label = path.split(\"\\\\\")[-1]\n",
    "        if label not in data_dict[\"label_map\"]:\n",
    "            data_dict[\"label_map\"].append(label)\n",
    "\n",
    "        for f in files:\n",
    "            # Add encoded label to encoded_labels list\n",
    "            index = data_dict['label_map'].index(label)\n",
    "            data_dict['encoded_labels'].append(index)\n",
    "\n",
    "            # Add file path to files list\n",
    "            data_dict['files'].append(os.path.join(path, f))\n",
    "\n",
    "            # Load audio and add MFCCs to list\n",
    "            y, sr = li.load(os.path.join(path, f), sr=None, mono=True)\n",
    "            mfccs = li.feature.mfcc(y=y, sr=sr, n_mfcc=mfcc_count, hop_length=hop, n_fft=fft_len)\n",
    "\n",
    "            # Cast np.array to list is needed to save as JSON file\n",
    "            data_dict['mfccs'].append(mfccs.transpose().tolist())\n",
    "\n",
    "    # Store in json file\n",
    "    if json_path:\n",
    "        with open(json_path, 'w') as jf:\n",
    "            json.dump(data_dict, jf, indent=4)\n",
    "            print(f'Successfully saved preprocessed data to {json_path}!')\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved preprocessed data to ..\\datasets\\british-birdsong-dataset\\preprocessed_data.json!\n"
     ]
    }
   ],
   "source": [
    "json_path = dataset_path + 'preprocessed_data.json'\n",
    "preprocessed_data = preprocess_audio_dataset(audio_path, json_path=json_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_audio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
