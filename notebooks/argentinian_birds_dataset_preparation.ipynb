{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import requests\n",
    "from time import sleep\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import librosa as li\n",
    "import soundfile as sf\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function definitions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate butterworth highpass coefficients\n",
    "def butter_highpass(cutoff, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    b, a = signal.butter(order, normal_cutoff, btype='high', analog=False)\n",
    "    return b, a\n",
    "\n",
    "\n",
    "# Apply filter to signal\n",
    "def apply_butter_highpass(data, cutoff, fs, order=5):\n",
    "    b, a = butter_highpass(cutoff, fs, order=order)\n",
    "    y = signal.filtfilt(b, a, data)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove sections of silence or low intensity signal\n",
    "def remove_silence(signal, thresh=18, hop=2048, plot=False):\n",
    "    splits = li.effects.split(y=signal, top_db=thresh, frame_length=(hop * 2), hop_length=hop)\n",
    "    if plot:\n",
    "        peak = np.max(signal)\n",
    "        plt.subplots(figsize=(12, 4))\n",
    "        plt.plot(signal)\n",
    "        plt.vlines(splits, ymin=-peak, ymax=peak, color='red')\n",
    "        plt.show()\n",
    "\n",
    "    stripped_audio = []\n",
    "\n",
    "    for s in splits:\n",
    "        split = signal[s[0] : s[1]]\n",
    "        stripped_audio.extend(split)\n",
    "\n",
    "    return np.asarray(stripped_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split audio into segments of desired length\n",
    "def split_audio(signal, target_length, samplerate, plot=False):\n",
    "    duration = li.get_duration(y=signal, sr=samplerate)\n",
    "    n_segments = np.ceil(duration / target_length)\n",
    "    audio_segments = []\n",
    "\n",
    "    for n in range(int(n_segments)):\n",
    "        s = signal[samplerate * n * target_length : samplerate * (n + 1) * target_length]\n",
    "\n",
    "        if len(s) < target_length * samplerate:\n",
    "            s = np.pad(s, (0, target_length * samplerate - len(s)), 'constant')\n",
    "\n",
    "        audio_segments.append(s)\n",
    "\n",
    "        if plot:\n",
    "            plt.plot(s, alpha=1 / n_segments)\n",
    "\n",
    "    if plot:\n",
    "        plt.show()\n",
    "\n",
    "    return audio_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply all signal processing functions to audio and return segments\n",
    "def generate_preprocessed_samples(path, sr, length, hp=700):\n",
    "\n",
    "    y, sr = li.load(path, sr=sr, mono=True)  # Load audio file\n",
    "\n",
    "    y = apply_butter_highpass(data=y, cutoff=hp, fs=sr, order=5)  # Apply high-pass filter\n",
    "\n",
    "    # Delete silent sections\n",
    "    y = remove_silence(y, thresh=20, hop=2048, plot=False)\n",
    "\n",
    "    audio_segments = split_audio(\n",
    "        y, target_length=length, samplerate=sr\n",
    "    )  # Split into segments of desired length\n",
    "\n",
    "    return audio_segments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio dataset download and preparation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_RECORDED_TIME = 120\n",
    "SPECIES_COUNT = 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database query and metadata generation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_location = '..\\\\datasets\\\\xeno-canto_argentina\\\\'\n",
    "\n",
    "# Query filters\n",
    "country = 'argentina'\n",
    "since = '2000-01-01'\n",
    "group = 'birds'\n",
    "length = '10-60'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "• Query result: status-code 200\n",
      "• Found 8694 recordings in 18 pages.\n"
     ]
    }
   ],
   "source": [
    "api_url = 'https://xeno-canto.org/api/2/recordings?query='\n",
    "params = f\"cnt:{country}+grp:{group}+len:{length}+since:{since}\"\n",
    "\n",
    "response = requests.get(api_url + params)\n",
    "\n",
    "print(f\"• Query result: status-code {response.status_code}\")\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "\n",
    "    n_rec = data[\"numRecordings\"]\n",
    "    pages = data[\"numPages\"]\n",
    "    print(f\"• Found {n_rec} recordings in {pages} pages.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created new folder: ..\\datasets\\xeno-canto_argentina\\\n",
      "Working on page 1...   Done!\n",
      "Working on page 2...   Done!\n",
      "Working on page 3...   Done!\n",
      "Working on page 4...   Done!\n",
      "Working on page 5...   Done!\n",
      "Working on page 6...   Done!\n",
      "Working on page 7...   Done!\n",
      "Working on page 8...   Done!\n",
      "Working on page 9...   Done!\n",
      "Working on page 10...   Done!\n",
      "Working on page 11...   Done!\n",
      "Working on page 12...   Done!\n",
      "Working on page 13...   Done!\n",
      "Working on page 14...   Done!\n",
      "Working on page 15...   Done!\n",
      "Working on page 16...   Done!\n",
      "Working on page 17...   Done!\n",
      "Working on page 18...   Done!\n"
     ]
    }
   ],
   "source": [
    "# Create dataset folder\n",
    "try:\n",
    "    os.mkdir(dataset_location)\n",
    "    print('Created new folder: ' + dataset_location)\n",
    "except:\n",
    "    try:\n",
    "        os.mkdir('..\\\\datasets')\n",
    "        os.mkdir(dataset_location)\n",
    "    except:\n",
    "        print(dataset_location + ' already exists\\n')\n",
    "\n",
    "# Store each page of the request into a Pandas dataframe\n",
    "df_list = []\n",
    "for page in range(1, pages + 1):\n",
    "    print(f'Working on page {page}...', end=\"   \")\n",
    "    response = requests.get(api_url + params + f\"&page={page}\")\n",
    "    data = response.json()\n",
    "    df = pd.json_normalize(data['recordings'])\n",
    "    df_list.append(df)\n",
    "    print('Done!')\n",
    "\n",
    "# Concatenate all dataframes into one and save to disk\n",
    "recordings_dataframe = pd.concat(df_list, ignore_index=True)\n",
    "recordings_dataframe.to_csv(dataset_location + 'metadata.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter metadata entries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minutes_to_seconds(mmss_time):\n",
    "    m, s = mmss_time.split(':')\n",
    "    return (int(m) * 60) + int(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    dataset_location + 'metadata.csv',\n",
    "    usecols=[\n",
    "        'id',\n",
    "        'group',\n",
    "        'gen',\n",
    "        'sp',\n",
    "        'ssp',\n",
    "        'en',\n",
    "        'loc',\n",
    "        'type',\n",
    "        'file',\n",
    "        'q',\n",
    "        'length',\n",
    "        'method',\n",
    "        'file-name',\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Clean metadata\n",
    "df = df.loc[\n",
    "    (df['group'] == 'birds')\n",
    "    & (df['gen'] != 'Mystery')\n",
    "    & (df['sp'] != 'mystery')\n",
    "    & (df['q'].isin(['A']))\n",
    "    & (df['method'] == 'field recording')\n",
    "    & (df['type'].isin(['call', 'song']))\n",
    "]\n",
    "\n",
    "# Convert length column from minutes to seconds for aggregation\n",
    "df['length'] = df['length'].map(minutes_to_seconds)\n",
    "\n",
    "# Group df by species and aggregate file length\n",
    "df_group = df.groupby(['gen', 'sp'], as_index=False).sum('length')\n",
    "\n",
    "# Get top n species with most recording time\n",
    "df_group = df_group.sort_values('length', ascending=False).iloc[:SPECIES_COUNT]\n",
    "selected_species = (df_group['gen'] + ' ' + df_group['sp']).values.tolist()\n",
    "\n",
    "# Filter recordings based on selected species\n",
    "df_filter = df.loc[(df['gen'] + ' ' + df['sp']).isin(selected_species)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download audio data from Xeno-Canto database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subfolders for each species\n",
    "audio_location = dataset_location + 'audio\\\\'\n",
    "\n",
    "os.mkdir(audio_location)\n",
    "for sp in selected_species:\n",
    "    os.mkdir(os.path.join(audio_location, sp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store currently downloaded audio time in a dictionary\n",
    "downloaded_time_per_species = dict.fromkeys(selected_species, 0)\n",
    "\n",
    "for index in df_filter.index:\n",
    "    # Get data from df row\n",
    "    species = df['gen'][index] + ' ' + df['sp'][index]\n",
    "    id = df['id'][index]\n",
    "    length = df['length'][index]\n",
    "    url = df['file'][index]\n",
    "    ext = df['file-name'][index].split('.')[-1]\n",
    "\n",
    "    # Download files for each species until max_recorded_time is reached\n",
    "    if (downloaded_time_per_species[species]) <= MIN_RECORDED_TIME:\n",
    "        downloaded_time_per_species[species] += length\n",
    "        \n",
    "        filename = f'{species}_{id}.{ext}'\n",
    "\n",
    "        with open(os.path.join(audio_location, species, filename), 'wb') as out_file:\n",
    "            content = requests.get(url, stream=True).content\n",
    "            out_file.write(content)\n",
    "        \n",
    "        # Wait required time between recordings\n",
    "        sleep(1.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert all files to FLAC 16bits/16kHz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_flac(audio_path, samplerate):\n",
    "    for i, (path, _, files) in enumerate(os.walk(audio_path)):\n",
    "        if path == audio_path:  # Ignore parent folder\n",
    "            continue\n",
    "\n",
    "        for f in files:\n",
    "            filename = os.path.join(path, f)\n",
    "            old_extension = filename.split('.')[-1]\n",
    "            y, sr = li.load(filename, sr=samplerate, mono=True)\n",
    "            sf.write(filename.replace(old_extension, 'flac'), y, sr, format='flac', subtype='PCM_16')\n",
    "            os.remove(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_RATE = 16000\n",
    "audio_path = '..\\\\datasets\\\\xeno-canto_argentina\\\\audio\\\\'\n",
    "\n",
    "convert_to_flac(audio_path, SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio preprocessing and feature extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target sample rate for resampling audio files\n",
    "SAMPLE_RATE = 16000\n",
    "\n",
    "# Target length for audio segments (in seconds)\n",
    "SAMPLE_LENGTH = 3\n",
    "\n",
    "dataset_path = '..\\\\datasets\\\\xeno-canto_argentina\\\\'\n",
    "audio_path = '..\\\\datasets\\\\xeno-canto_argentina\\\\audio\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: fix function so it does not load all MFCCs into memory\n",
    "\n",
    "def preprocess_audio_dataset(data_path, json_path=None, mfcc_count=13, hop=512, fft_len=2048):\n",
    "    data_dict = {\n",
    "    'label_map': [],\n",
    "    'encoded_labels': [],\n",
    "    'mfccs': [],\n",
    "    'files': [],\n",
    "    }\n",
    "\n",
    "    for i, (path, _, files) in enumerate(os.walk(data_path)):\n",
    "        if path == data_path:  # Ignore parent folder\n",
    "            continue\n",
    "\n",
    "        # Add unique labels to label_map list\n",
    "        label = path.split('\\\\')[-1]\n",
    "        if label not in data_dict['label_map']:\n",
    "            data_dict['label_map'].append(label)\n",
    "\n",
    "        for f in files:\n",
    "            segments = generate_preprocessed_samples(os.path.join(path, f), sr=SAMPLE_RATE, length=SAMPLE_LENGTH)\n",
    "            for segment in segments:\n",
    "                # Add encoded label to encoded_labels list\n",
    "                index = data_dict['label_map'].index(label)\n",
    "                data_dict['encoded_labels'].append(index)\n",
    "\n",
    "                # Add original file path to files list\n",
    "                data_dict['files'].append(os.path.join(path, f))\n",
    "\n",
    "                # Compute MFCCs\n",
    "                mfccs = li.feature.mfcc(y=segment, sr=SAMPLE_RATE, n_mfcc=mfcc_count, hop_length=hop, n_fft=fft_len)\n",
    "\n",
    "                # Append MFCCs to list. Casting np.array to list for saving as JSON file.\n",
    "                data_dict['mfccs'].append(mfccs.transpose().tolist())\n",
    "\n",
    "    # Store data dictionary in JSON file\n",
    "    if json_path:\n",
    "        with open(json_path, 'w') as jf:\n",
    "            json.dump(data_dict, jf, indent=4)\n",
    "            print(f'Successfully saved preprocessed data to {json_path}!')\n",
    "            file_count = len(data_dict['files'])\n",
    "            print(f'{file_count} audio samples were processed!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved preprocessed data to ..\\datasets\\xeno-canto_argentina\\preprocessed_data.json!\n",
      "1389 audio samples were processed!\n"
     ]
    }
   ],
   "source": [
    "json_path = dataset_path + 'preprocessed_data.json'\n",
    "preprocess_audio_dataset(audio_path, json_path=json_path, mfcc_count=13)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_audio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
